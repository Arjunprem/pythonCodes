{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arjun Premkumar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://interface-experience.org/site/wp-content/uploads/2015/01/IE-014g-1000x734.jpg\" width=140> <img src=\"http://interface-experience.org/site/wp-content/uploads/2015/01/IE-017f-563x750.jpg\" width=77> <img src=\"http://interface-experience.org/site/wp-content/uploads/2015/01/IE-018a-605x750.jpg\" width=83> <img src=\"http://interface-experience.org/site/wp-content/uploads/2015/01/IE-021c-605x750.jpg\" width=84> <img src=\"http://interface-experience.org/site/wp-content/uploads/2015/01/IE-019-1000x689.jpg\" width=150> <img src=\"http://interface-experience.org/site/wp-content/uploads/2015/01/IE-032-621x750.jpg\" width=87>\n",
    "## COM110 Programming Assignment 3:\n",
    "### Processing Audio in the WAV format (.wav files)\n",
    "<img src=\"https://t4.ftcdn.net/jpg/03/27/36/95/360_F_327369570_CAxxxHHLvjk6IJ3wGi1kuW6WTtqjaMpc.jpg\" width=\"600\">\n",
    "(c) 2023 Timothy Becker, Department of Computer Science <br><br>\n",
    "<img src=\"https://www.conncoll.edu/media/website-media/visualidentity/images/1Line-LogoSig-Color.jpg\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "For this assignment you should pick either <b>Path A</b> or <b>Path B</b> to complete based on your interests. You should start by downloading this notebook (Program_1.ipynb) and move it into your preferred jupyter lab location such as: /User/Documents/COM110. Then you can launch the notebook from the command line or the anaconda navigator app and work directly on it, making sure to complete the important first cell which should have your name and not FirstName LastName!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 1\n",
    "#### Reading and Writing WAV format audio files\n",
    "\n",
    "We will develop some python3 code using the scientific module called [scipy](https://docs.scipy.org/doc/scipy/tutorial/index.html#user-guide). This particular module is designed to provide algorithms that solve a large amount of problems common in scientific and engineering workflows (such as optimization, eigen-value, differential, integration and statistical analysis). It makes use of [numpy](https://numpy.org/devdocs/user/quickstart.html) which is a library that provides efficient objects called n-dimensional arrays to use (instead of the regular python list). We will use these arrays to store in RAM the digital representation of an audio file in the WAV format. Audio files are nothing more than a series of numbers that represent an instantaneous amplitude of an acoustic waveform. Follow this link and read some background about that [here](https://docs.cycling74.com/max5/tutorials/msp-tut/mspdigitalaudio.html). You do not have to master the understanding of acoustics to proceed however! You will use loops and will make use of what you are learning in Object Orientated Design (OOD) in this assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy' has no attribute 'io'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sr,data \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241m.\u001b[39mwavfile\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mString_Quart.wav\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#read the attached String Quartet File\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sr,data\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'scipy' has no attribute 'io'"
     ]
    }
   ],
   "source": [
    "sr,data = scipy.io.wavfile.read('String_Quart.wav') #read the attached String Quartet File\n",
    "sr,data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This audio file is a recording excerpt from a String Quartet which has two violins, one viola and one cello. This recording is in mono which means there is only one channel of audio here, which will make a 1D array (similar to a list). When a WAV file is read it can encode the audio using different data sizes such as 16-bit int, or the new state of the art 32-bit floting point. The first number you see in the output is the sample rate of the audio which is very important since it controls how fast the file is played!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.shape #this will tell us how many total samples are in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdata\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "len(data) #similiar to length but the numpy specific shape is more useful when we start to deal with higher dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making an edit (save it to a new variable name to be non-destructive to original) and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit = data[data.shape[0]//2:]               #skip past the first half of the file\n",
    "scipy.io.wavfile.write('Edit1.wav',sr,edit) #the file I want to make, the sample rate and the data to feed it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1a 10 pts] Edit and Save Beginning Half\n",
    "Edit the contents of the data array (store in a new variable called edit) and save the result to a WAV file on your own using the above examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#your code here\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m edit \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m[:data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m]               \u001b[38;5;66;03m#skip past the first half of the file\u001b[39;00m\n\u001b[1;32m      3\u001b[0m scipy\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mwavfile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEdit.wav\u001b[39m\u001b[38;5;124m'\u001b[39m,sr,edit)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "edit = data[:data.shape[0]//2]               #skip past the first half of the file\n",
    "scipy.io.wavfile.write('Edit.wav',sr,edit) #the file I want to make, the sample rate and the data to feed it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1b 10pts] Reverse the Audio File\n",
    "You should now reverse the contents of data, saving your result in edit and then write that file as above. Two main ways are to use the built in indexing (there is an example in previous LABs) or you can use a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "edit = data[:data.shape[0]//2:-1]               #skip past the first half of the file\n",
    "scipy.io.wavfile.write('Edit.wav',sr,edit) #the file I wa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1c 10pts] Adjust Sample Rate\n",
    "Next you will play around with the sample rate value. Specifically, experiment with adjusting the sample rate by multiplication or division of an integer number like 2,3, etc. Listen to the result and see if you can hear any differences in the original audio file and your new one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "edit = data[:data.shape[0]//2:3]               #skip past the first half of the file\n",
    "scipy.io.wavfile.write('Edit.wav',sr,edit) #the file I wa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1d 10pts] Adjust Loudness\n",
    "Now you can try to make the file very quiet by dividing the amplitude (divide the whole data array). Multiplying a waveform makes it louder and dividing it makes it softer. Experiement with this by using a scaling factor of 8 or more. You should be able to hear your result when you play it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "edit = data[:data.shape[0]//2:3]  /8             #skip past the first half of the file\n",
    "scipy.io.wavfile.write('Edit.wav',sr,edit) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "#### Using scipy as an audio processor (Digital Signal Processing: DSP)\n",
    "Now we will make use of the scipy library to make other changes to the sound other than loudness, sample rate and trimming start and end points. Here we will read in a WAV of spoken number 1 to 10. We are very sensitive to changes in voice and so this is a good file to use as a starting value, since it will make it easier to hear changes. This second file is also stereo which means we will have to modify our editing code to be more generalizable. In general WAV files have 1 or more channels of audio with music reading usually have 2 and movies that we watch have 8 (7.1 is 7 main channels and a separate channel for sub/low frequency effects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy' has no attribute 'io'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sr,data \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241m.\u001b[39mwavfile\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpoken_Numbers.wav\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#read the attached String Quartet File\u001b[39;00m\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m data[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m sr,data\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'scipy' has no attribute 'io'"
     ]
    }
   ],
   "source": [
    "sr,data = scipy.io.wavfile.read('Spoken_Numbers.wav') #read the attached String Quartet File\n",
    "data = data[:,0]\n",
    "sr,data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot the waveform to help us visualize what we are doing by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def audio_plot(data):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "    t = np.linspace(0.,len(edit)/sr,len(edit))\n",
    "    ax.plot(t,edit,lw=1)\n",
    "    plt.show() \n",
    "\n",
    "audio_plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally it would be nice if we could play the audio directly from the buffer instead of rendering to storage (writing a file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "\n",
    "def play(x,sr):\n",
    "    display(Audio(x,rate=sr, autoplay=False))\n",
    "\n",
    "play(data,sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example 1] Next we will filter out high frequencies and leave the low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass(data,sr,fr):\n",
    "    b,a  = scipy.signal.butter(2,fr/(sr/2.0),'low') #make a fr HZ cutoff low-pass filter\n",
    "    edit = scipy.signal.filtfilt(b,a,data)          #apply it to the data in RAM\n",
    "    edit = np.asarray(edit,dtype=np.int16)          #convert back into int16\n",
    "    return edit\n",
    "\n",
    "scipy.io.wavfile.write('LP_Filt.wav',sr,low_pass(data,sr,500)) #use 500 Hz frew and save the result to listen to it!\n",
    "play(edit,sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Exercise 1] Change the frequency of the filter and make sure it sounds different by listening to it with the play button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy' has no attribute 'io'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#your code here\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241m.\u001b[39mwavfile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLP_Filt.wav\u001b[39m\u001b[38;5;124m'\u001b[39m,sr,low_pass(data,sr,\u001b[38;5;241m500\u001b[39m)) \u001b[38;5;66;03m#use 500 Hz frew and save the result to listen to it!\u001b[39;00m\n\u001b[1;32m      3\u001b[0m play(edit,sr)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'scipy' has no attribute 'io'"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "scipy.io.wavfile.write('LP_Filt.wav',sr,low_pass(data,sr,500)) \n",
    "sr,edit=scipy.io.wavfile.read('LP_Filt.wav')\n",
    "play(edit,sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example 2] Or filter out high frequencies and leave low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     edit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(edit,dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint16)           \u001b[38;5;66;03m#convert back into int16\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m edit\n\u001b[0;32m----> 7\u001b[0m \u001b[43mscipy\u001b[49m\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mwavfile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHP_Filt.wav\u001b[39m\u001b[38;5;124m'\u001b[39m,sr,hi_pass(data,sr)) \u001b[38;5;66;03m#do 2000Hz frew and save the result to listen to it!\u001b[39;00m\n\u001b[1;32m      8\u001b[0m play(edit,sr)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "def hi_pass(data,sr,fr):\n",
    "    b,a  = scipy.signal.butter(2,fr/(sr/2.0),'high') #make a fr HZ cutoff hi-pass filter\n",
    "    edit = scipy.signal.filtfilt(b,a,data)           #apply it to the data in RAM\n",
    "    edit = np.asarray(edit,dtype=np.int16)           #convert back into int16\n",
    "    return edit\n",
    "\n",
    "scipy.io.wavfile.write('HP_Filt.wav',sr,hi_pass(data,sr)) #do 2000Hz frew and save the result to listen to it!\n",
    "play(edit,sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Exercise 2] Change the frequency of the filter and see if you can hear a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "scipy.io.wavfile.write('HP_Filt.wav',sr,hi_pass(data,sr,5000))\n",
    "sr,edit=scipy.io.wavfile.read('LP_Filt.wav')\n",
    "play(edit,sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example 3] Or take a reduced amplitude and delay it (shift it a number of samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delay(data,sr,ts):\n",
    "    edit = np.zeros(data.shape,dtype=np.int16)\n",
    "    edit[:] = data[:]\n",
    "    for s in ts:\n",
    "        edit[:len(edit)-int(s*sr)] += data[int(s*sr):]//2\n",
    "    return edit\n",
    " \n",
    "edit = delay(data,sr,[0.1,0.2,0.3,0.5,0.7,0.9])\n",
    "\n",
    "audio_plot(edit)\n",
    "play(edit,sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Exercise 3] Make a reverse_delay function that uses delayed reversed audio. Hint: an easy way to reverse the contents of an array named xs would be:<br> xs = xs[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "edit = delay(data,sr,[0.1,0.2,0.3,0.5,0.7,0.9])\n",
    "abc= edit[::-1]\n",
    "\n",
    "audio_plot(abc)\n",
    "play(edit,sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Example 4] Shift the frequencies of the audio. This one is really fun! It uses a Discrete Cosine Transform (DCT) to convert the audio from its normal time domain into the frequency domain. The shifing is applied while the data is in frequency domain and then the inverse DCT (idct) converts it back into time domain so you can hear the result. More information about the DCT is [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.fft.dct.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft, fftfreq, ifft\n",
    "\n",
    "def shifter(data,shift,sr):\n",
    "    shifter = -3000\n",
    "    d = scipy.fft.dct(data)\n",
    "    p = scipy.ndimage.shift(d,shifter-3000,cval=0.0)\n",
    "    edit = scipy.fft.idct(p)\n",
    "    return edit\n",
    "\n",
    "edit = shifter(data,-4000,sr)\n",
    "audio_plot(edit)\n",
    "play(edit,sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Exercise 4] Use the code above to shift the frequencies of the source material using the shifter function. Can you make the pitch higher instead of lower?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     edit \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39midct(p)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m edit\n\u001b[0;32m----> 9\u001b[0m edit \u001b[38;5;241m=\u001b[39m shifter(\u001b[43mdata\u001b[49m,\u001b[38;5;241m3000\u001b[39m,sr)\n\u001b[1;32m     10\u001b[0m audio_plot(edit)\n\u001b[1;32m     11\u001b[0m play(edit,sr)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "def shifter(data,shift,sr):\n",
    "    shifter = +4000\n",
    "    d = scipy.fft.dct(data)\n",
    "    p = scipy.ndimage.shift(d,shifter +4000,cval=0.0)\n",
    "    edit = scipy.fft.idct(p)\n",
    "    return edit\n",
    "\n",
    "edit = shifter(data,2000,sr)\n",
    "audio_plot(edit)\n",
    "play(edit,sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "#### Designing an AudioEdit object\n",
    "\n",
    "We have many examples from above that are all following a particuliar type of workflow. This is the application part of the program where you will need to design a new python type that will make processing the WAVs above in Part 1 and Part 2 much easier. You are only designing the class and the code for using the class will be already supllied in the cells below. Writting classes must follow the rules of encapsulation which means you need to create internal variables (instance variables) and then write the coresponding functions for accessing the data (accessor) and saving/updating internal data (mutator). You will be given some hints as you work through your design. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[step 1] Make a new python file and make sure it is located in the save location (folder/directory) as this .ipynb file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[step 2] use the class keyword and make your file and class name: AudioEdit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[step 3] Make internal variables called data and set it to None and sr (stands for sample rate) and do the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "sr   = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[step 4] Write the constructor so that is takes the WAV file path as its input. You will need to make sure you have downloaded the example WAV files and that you are able to Read/Write and Play the audio in the Part 1 and Part 2 first. The function signature will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self,wav_file) #remember this needs to go inside the class body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This constructor should then read the wav_file and save the result of the data to the self.data variable and should save the sr to the self.sr variable in the AudioEdit class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[step 4] Write the audio processors above (there are 4 of them) and write these as mutator method for your class. Instead of reading from an input parameter, your method should read from self.data and make a local copy using the variable edit and then save the result to self.data. An example is shown below for a reversal (not one of the 4 you need to do):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse(self):      #remember this needs to go inside the class body\n",
    "    edit = self.data[:] #make a copy of the audio data to local variable edit\n",
    "    self.data = edit    #save/update the self.data audio, notice there is no return here!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[step 5] Now you will write a save method which will save the result to disk, the play method which produces the playback widget, the plot method which are all differnt type of accessor methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[step final] Now test it out using the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (AudioEdit.py, line 6)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3369\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  Input \u001b[0;32mIn [5]\u001b[0;36m in \u001b[0;35m<cell line: 1>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from AudioEdit import AudioEdit\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Documents/COM110/Program 3 COM-110/AudioEdit.py:6\u001b[0;36m\u001b[0m\n\u001b[0;31m    class AudioEdit\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from AudioEdit import AudioEdit\n",
    "audio = AudioEdit('String_Quart.wav')  #read in the WAV file\n",
    "audio.shift(-3000)                     #frequency shift down\n",
    "audio.low_pass(2000.0)                 #filter out high frequncies past 2000Hz\n",
    "audio.delay([0.1,0.2,0.3])             #add three delays\n",
    "audio.hi_pass(100.0)                   #filter out low frequencies past 100 Hz\n",
    "audio.plot()                           #visualize the waveform\n",
    "audio.play()                           #platback so you can debug results\n",
    "audio.save(\"Final.wav\")                #save the result WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
